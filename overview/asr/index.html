<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-overview/asr">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Anticipatory Story Reader | OpenSherlock</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://opensherlock.github.io/img/opensherlock-social-card.png"><meta data-rh="true" name="twitter:image" content="https://opensherlock.github.io/img/opensherlock-social-card.png"><meta data-rh="true" property="og:url" content="https://opensherlock.github.io/overview/asr/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Anticipatory Story Reader | OpenSherlock"><meta data-rh="true" name="description" content="- Why?"><meta data-rh="true" property="og:description" content="- Why?"><link data-rh="true" rel="icon" href="/img/cooperation.svg"><link data-rh="true" rel="canonical" href="https://opensherlock.github.io/overview/asr/"><link data-rh="true" rel="alternate" href="https://opensherlock.github.io/overview/asr/" hreflang="en"><link data-rh="true" rel="alternate" href="https://opensherlock.github.io/overview/asr/" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.16e4fda8.css">
<link rel="preload" href="/assets/js/runtime~main.2d7695f7.js" as="script">
<link rel="preload" href="/assets/js/main.4bb36c3b.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/cooperation.svg" alt="OpenSherlock" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/cooperation.svg" alt="OpenSherlock" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">OpenSherlock</b></a><a class="navbar__item navbar__link" href="/introduction/">Introduction</a><a class="navbar__item navbar__link" href="/roadmap/">Roadmap</a><a class="navbar__item navbar__link" href="/collaboration/">Collaboration</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/OpenSherlock" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/introduction/">Introduction</a><button aria-label="Toggle the collapsible sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/overview/">System Overview</a><button aria-label="Toggle the collapsible sidebar category &#x27;System Overview&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/overview/asr/">Anticipatory Story Reader</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/roadmap/">Project Roadmap</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/references/">References</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/collaboration/">Collaboration</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/overview/"><span itemprop="name">System Overview</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Anticipatory Story Reader</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Anticipatory Story Reader</h1><ul><li>Why?</li><li>How?</li><li>Underlying algorithms, techniques</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="why">Why<a href="#why" class="hash-link" aria-label="Direct link to Why" title="Direct link to Why">â€‹</a></h3><p>Anticipatory Story Reader (ASR) gets its name from a machine reading process which simulates that of a young child learning to read.<br>
<!-- -->A primary goal of ASR is to grow and maintain a world model, one which can span many domains of knowledge and discourse.
ASR emerged out of two goals:</p><ul><li>To explore the ways in which a child, at once, learns how to read, and learns by reading</li><li>To remember everything it reads
Those goals entail to important features:</li><li>Anticipatory behavior: dealing with those &quot;expectation failures&quot; which happen when some, say, sentence cannot be processed.  Note that not all sentences can, in fact, be processed into anything which fits OpenSherlock&#x27;s needs.</li><li>Data compression. Benefits include transparency and tracaability back to sources.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-asr-introduction">How: ASR Introduction<a href="#how-asr-introduction" class="hash-link" aria-label="Direct link to How: ASR Introduction" title="Direct link to How: ASR Introduction">â€‹</a></h3><p>A side effect of ASR&#x27;s processes is that of massive data compression.  ASR is able to remember everything it reads without bloating databases.  It records each sentence one and only one time, but turns unique terms and predicates in that sentence into numeric identifiers just one time. Further processing is based on those identifiers.
Anticipatory behaviors are model driven. That is, a reader&#x27;s domain model, no matter how complete or sophisticated, is actively engaged in the reading process.  If the reader encounters something it did not expect, meaning, its model did not predict that event, then there is an expectation failure.  How the reader deals  with such failures is one way to think about intelligence gained from experience.  Frequently, a human reader reacts first by re-reading the passage, followed by &quot;looking around&quot; for hints.  In a child&#x27;s book, pictures or images provide hints.<br>
<!-- -->In machine reading, as in ASR, there is a cascade of expectation failure handlers, depending on the nature of the failure, ending with &quot;Ask a Human&quot; - that is, create a log of failures not solved for humans to examine.
For humans, one kind of failure is encountering a new word or term.  That might lead to finding the term online or by other means.  For ASR, that&#x27;s not an expectation failure; the system simply creates a new Dictionary entry for it, and adds it to the WordGram graph.
Another kind of failure is one in which a statment encountered by a human contradicts what her model expected.  For ASR, that&#x27;s not an expectation failure simply because the system records the new claim for what it is, then connects that claim to the one it contradicts with a &quot;disagreesWith&quot; coherence relation.  It is ASR&#x27;s task to grow models as complete as possible, not to resolve contradictons.
For ASR, an important expectation failure is one in which an entire sentence does not parse.  That is, no nouns or noun phrases are found, and therefore, no claims are found.  That failure is passed to humans. In fact, not all sentences contain claims.
From that, we see that ASR does not use its growing domain model in the way humans do; humans deal with expectation failures, whereas ASR uses them to grow the model with coherence relations where necessary.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="asr-agents">ASR Agents<a href="#asr-agents" class="hash-link" aria-label="Direct link to ASR Agents" title="Direct link to ASR Agents">â€‹</a></h3><p>ASR is a society of agents, each coordinated by passing messages on topic-centric channels over a Redis database.  In the largest picture, the process begins with document ingestion followed by document processing, then to parsing, and beyondâ€¦</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="nlp-harvest">nlp-harvest<a href="#nlp-harvest" class="hash-link" aria-label="Direct link to nlp-harvest" title="Direct link to nlp-harvest">â€‹</a></h4><p>This is the document ingestion process, which reads both PubMed abstracts and PMC full text documents, and converts those to JsonObjects by way of the JSONDocumentObject pojo.<br>
<!-- -->It then creates database entries for each IDocument represented by that JsonObject. For each paragraph in that IDocument, it creates a database entry based on an IParagraph object.
Finally, it sends each IParagraph&#x27;s JsonObject out over Redis.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="nlp-parser">nlp-parser<a href="#nlp-parser" class="hash-link" aria-label="Direct link to nlp-parser" title="Direct link to nlp-parser">â€‹</a></h4><p>This process reads IParagraph objects in from Redis.
It then passes each through a process which, first, isolates all sentences into an array.  That same process identifies anaphoric references in the paragraph and returns a JsonObject for later use.
For each sentence, a database entry is created based on an ISentence object, and, together with the anaphoric reference object, parsing begins.
Parsing entails three processes:</p><ul><li>OpenNLP processing</li><li>spaCy processing</li><li>LLM processing</li></ul><p>Those three processes create JsonObjects which contain a variety of resources, such as</p><ul><li>POS array for all words in the sentence</li><li>Anaphoric reference links</li><li>Identified predicate phrases</li><li>Named entities</li><li>Hearst patterns - automatic detection of hypernyms and hyponyms</li><li>DBpedia and WikiData identifiers</li><li>Other objectsâ€¦
All named entities and predicate phrases are added to the Dictionary, if not already there, and to the WordGram graph.  Sentence IDs are accumulated in each IWordGram.
Note: </li><li>Predicate phrases are critical features</li><li>we normalize them.  As an example, the phrase &quot;has frequently been shown to affect&quot;  is normalized to &quot;affects&quot;</li><li>Negative phrases such as &quot;is not connected to&quot; or &quot;does not cause&quot; maps to &quot;notConnectedTo&quot; or &quot;notCause&quot;</li><li>Passive predicates such as &quot;isCausedBy&quot; is mapped to &quot;cause&quot; and a trigger is set to cause a reversal of the triple structure: subject swaps with object. We normalize to active predicates.
A goal of this parsing is to capture frame-like representations, with a simple triple object, e.g. {A, cause, B} being the smallest frame.  Frame structures can be added to the WordGramGraph.
Frame structures are sent to Redis.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="nlp-world-model">nlp-world-model<a href="#nlp-world-model" class="hash-link" aria-label="Direct link to nlp-world-model" title="Direct link to nlp-world-model">â€‹</a></h4><p>This agent&#x27;s primary objective is to use frame structures from Redis and create and maintain a graph structure which properly reflects those structures it encounters.
During this process, it may encounter claims which contradict claims it already has stored, at which point, it connects them with appropriate coherence relations.
A proper world model must include authors, their affiliations, and even funding agencies, together with the  documents cited. Each is its own subject.   Wiring them into a graph aids when the system encounters an ambiguity for which it issues an expectation failure.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="underlying-algorithm-techniques">Underlying Algorithm Techniques<a href="#underlying-algorithm-techniques" class="hash-link" aria-label="Direct link to Underlying Algorithm Techniques" title="Direct link to Underlying Algorithm Techniques">â€‹</a></h3><ul><li>TODO</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="glossary">Glossary<a href="#glossary" class="hash-link" aria-label="Direct link to Glossary" title="Direct link to Glossary">â€‹</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ambiguity">Ambiguity<a href="#ambiguity" class="hash-link" aria-label="Direct link to Ambiguity" title="Direct link to Ambiguity">â€‹</a></h4><p>A typical ambiguity occurs when a particular IWordGram&#x27;s term serves as a label for more than one subject in the world model.
Wikipedia addressed this issue by adding some property to that name, in parentheses, and then offers a &quot;disambiguation&quot; page.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="dictionary">Dictionary<a href="#dictionary" class="hash-link" aria-label="Direct link to Dictionary" title="Direct link to Dictionary">â€‹</a></h4><p>A Dictionary provides a way to map a word or term to a numeric identifier, and back.
For each word or term, there will be one and only one Dictionary entry.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="expectationfailure">ExpectationFailure<a href="#expectationfailure" class="hash-link" aria-label="Direct link to ExpectationFailure" title="Direct link to ExpectationFailure">â€‹</a></h4><p>A general class which can include many failure types, each of which is created by, in general, some failure to parse a sentence.
Over time, the list of failure types will grow.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="frame">Frame<a href="#frame" class="hash-link" aria-label="Direct link to Frame" title="Direct link to Frame">â€‹</a></h4><p>That term got its name in the 1950&#x27;s when Charles Fillmore invented Case Frames, which Marvin Minski later just called &quot;Frames&quot;.  A Frame if best thought of as a collection of properties and their values, with an identity given to that collection.  The Lisp programming language naturally assembles frames with property lists.
Today, we can represent frames in XML, JSON, and  programmatically in classes which have identy and property lists.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="hearst-pattern">Hearst Pattern<a href="#hearst-pattern" class="hash-link" aria-label="Direct link to Hearst Pattern" title="Direct link to Hearst Pattern">â€‹</a></h4><p>Marti Hearst at UC Berkeley is credited with creating a set of syntactic patterns which allow to identify, among other things, hypernyms.  For example, this sentence:</p><ul><li>I have friends such as Sue, Bob, and Joe
can tell ASR that Sue, Bob, and Joe are hypernyms of the concept of &quot;my friends&quot;.  If that sentence was processed into the WordGramGraph, each IWordGram would have a hypernym edge to the &quot;my friends&quot; IWordGram.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="idocument">IDocument<a href="#idocument" class="hash-link" aria-label="Direct link to IDocument" title="Direct link to IDocument">â€‹</a></h4><p>This object defines a frame-like container which knows about the document&#x27;s attributes, such as</p><ul><li>Title</li><li>Abstract (we may not store the text, but rather the IParagraph identifiers related to the abstract)</li><li>Authors and their affiliations</li><li>An array of its IParagraph object identifiers for any body text.</li><li>Citations
Its purpose is to give that document a unique database identity.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="iparagraph">IParagraph<a href="#iparagraph" class="hash-link" aria-label="Direct link to IParagraph" title="Direct link to IParagraph">â€‹</a></h4><p>This object serves to contain:</p><ul><li>The paragraph itself (might not do this because we can reconstruct it from ISentence identifiers)</li><li>An array of its ISentence Identifiers</li><li>Some metadata from parsing
Its purpose is to give that paragraph a unique database identity.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="isentence">ISentence<a href="#isentence" class="hash-link" aria-label="Direct link to ISentence" title="Direct link to ISentence">â€‹</a></h4><p>This object serves to contain:</p><ul><li>The sentence itself  (this may be the only place we actually store a whole sentence</li><li>Some metadata from parsing - note that if a sentence is involved in an ExpectaionFailure, that metadata may be useful in failure handling
Its purpose is to give that sentence a unique database identity.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="iwordgram">IWordGram<a href="#iwordgram" class="hash-link" aria-label="Direct link to IWordGram" title="Direct link to IWordGram">â€‹</a></h4><p>This object is, itself, a tiny frame structure with identity granted to it by the Dictionary.  It contains terminals (single words) or phrases. Thus, e.g., the entire name &quot;George H.W.Bush&quot; would be captured in a single WordGram.  That frame also records the identity of every sentence in which it was encountered.
If that term happens to be the label in one (or more) subjects in the WorldModel, the identity of those subjects is also recorded.
Features like POS, and others are also recorded.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="pos">POS<a href="#pos" class="hash-link" aria-label="Direct link to POS" title="Direct link to POS">â€‹</a></h4><p>Part of speech, e.g &#x27;noun&#x27;. POS parsing typically returns more than just the pos itself, typically including other features.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="wordgramgraph">WordGramGraph<a href="#wordgramgraph" class="hash-link" aria-label="Direct link to WordGramGraph" title="Direct link to WordGramGraph">â€‹</a></h4><p>A graph of all IWordGram objects. As a graph, its edges include sentence ID values; that is, WordGrams are wired together by the sentences in which the are encountered.
Other edges can include synonyms, hyponyms, and hypernyms, where known.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/OpenSherlock/opensherlock.github.io/edit/main/docs/2-overview/3-asr.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/overview/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">System Overview</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/roadmap/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Project Roadmap</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why" class="table-of-contents__link toc-highlight">Why</a></li><li><a href="#how-asr-introduction" class="table-of-contents__link toc-highlight">How: ASR Introduction</a></li><li><a href="#asr-agents" class="table-of-contents__link toc-highlight">ASR Agents</a></li><li><a href="#underlying-algorithm-techniques" class="table-of-contents__link toc-highlight">Underlying Algorithm Techniques</a></li><li><a href="#glossary" class="table-of-contents__link toc-highlight">Glossary</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 TopicQuests. All Rights Reserved.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.2d7695f7.js"></script>
<script src="/assets/js/main.4bb36c3b.js"></script>
</body>
</html>